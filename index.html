<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/xingcheng.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/xingcheng.github.io/assets/img/profile.jpg"/><link rel="stylesheet" href="/xingcheng.github.io/_next/static/css/bced8c83fdf6512f.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/xingcheng.github.io/_next/static/chunks/webpack-d345df75e1a7ed31.js"/><script src="/xingcheng.github.io/_next/static/chunks/fd9d1056-58793f44b8517ebb.js" async=""></script><script src="/xingcheng.github.io/_next/static/chunks/117-dcda7d5517c78842.js" async=""></script><script src="/xingcheng.github.io/_next/static/chunks/main-app-9bd28de0294d09f4.js" async=""></script><script src="/xingcheng.github.io/_next/static/chunks/254-87337e6e5877cb9f.js" async=""></script><script src="/xingcheng.github.io/_next/static/chunks/app/page-af3d24cbd518d795.js" async=""></script><script src="/xingcheng.github.io/_next/static/chunks/app/layout-dfcfffdb162e0cfc.js" async=""></script><link rel="icon" href="/xingcheng.github.io/favicon.ico"/><title>Xingcheng Zhou | TUM</title><meta name="description" content="Vision Language Action research for autonomous driving and intelligent infrastructure"/><meta name="author" content="Xingcheng Zhou"/><meta name="keywords" content="autonomous driving,vision language model,world model,trajectory planning,cooperative perception,dataset,TUM"/><meta property="og:title" content="Xingcheng Zhou | TUM"/><meta property="og:description" content="Vision Language Action research for autonomous driving and intelligent infrastructure"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Xingcheng Zhou | TUM"/><meta name="twitter:description" content="Vision Language Action research for autonomous driving and intelligent infrastructure"/><meta name="next-size-adjust"/><script src="/xingcheng.github.io/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_8dd892"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&false)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}else{c.add('light')}if(e==='light'||e==='dark'||!e)d.style.colorScheme=e||'light'}catch(e){}}()</script><div class="flex min-h-screen flex-col"><nav class="sticky top-0 z-50 border-b bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60"><div class="container mx-auto px-4"><div class="flex h-16 items-center justify-between"><a class="text-xl font-semibold" href="/xingcheng.github.io">Xingcheng Zhou</a><div class="flex items-center gap-4"><div class="hidden md:flex md:gap-1"><a class="px-3 py-2 text-sm transition-colors text-primary font-medium" href="/xingcheng.github.io">Home</a><a class="px-3 py-2 text-sm transition-colors text-muted-foreground hover:text-foreground" href="/xingcheng.github.io#publications">Publications</a><a class="px-3 py-2 text-sm transition-colors text-muted-foreground hover:text-foreground" href="/xingcheng.github.io#national-projects">National Projects</a><a class="px-3 py-2 text-sm transition-colors text-muted-foreground hover:text-foreground" href="/xingcheng.github.io#academic-service">Academic Service</a></div></div></div></div></nav><main class="flex-1"><div class="container mx-auto px-4 py-8"><section class="py-12 border-b"><div class="grid gap-8 md:grid-cols-[1fr_250px]"><div class="space-y-6"><div class="prose prose-lg max-w-none dark:prose-invert"><p>Hi, I am Xingcheng Zhou. I joined the <a href="https://www.ce.cit.tum.de/air/" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">Chair of Robotics, Artificial Intelligence and Real time Systems</a> at Technical University of Munich in 2023 as a Research Associate, working under the supervision of <a href="https://www.ce.cit.tum.de/air/people/alois-knoll" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">Prof. Dr. Ing. habil. Alois Christian Knoll</a>.</p><p>My research interests include Vision Language Models, 3D Environment Perception, Scene Understanding, World Models and related areas.</p><p>I completed my M.Sc. in Electrical and Computer Engineering at the <a href="https://www.tum.de" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">Technical University of Munich</a> in 2021. Before joining TUM, I worked as an Industrial AI Researcher at <a href="https://www.siemens.com" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">Siemens</a>.</p></div><ul class="space-y-1 text-sm"><li>email:<!-- --> <a href="mailto:xingcheng.zhou@tum.de" class="text-primary hover:underline">xingcheng[dot]zhou{at}tum[dot]de</a></li></ul><div class="flex flex-wrap gap-4 items-center"><a target="_blank" rel="noopener noreferrer" class="text-2xl text-foreground hover:text-primary transition-colors" aria-label="Email" href="mailto:xingcheng.zhou@tum.de"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-6 w-6"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="text-2xl text-foreground hover:text-primary transition-colors" aria-label="Google Scholar" href="https://scholar.google.com/citations?user=FPYXLpQAAAAJ"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-graduation-cap h-6 w-6"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z"></path><path d="M22 10v6"></path><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="text-2xl text-foreground hover:text-primary transition-colors" aria-label="GitHub" href="https://github.com/ge25nab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-6 w-6"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="text-2xl text-foreground hover:text-primary transition-colors" aria-label="TUM Profile" href="https://www.ce.cit.tum.de/air/people/xingcheng-zhou-msc/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-building2 h-6 w-6"><path d="M6 22V4a2 2 0 0 1 2-2h8a2 2 0 0 1 2 2v18Z"></path><path d="M6 12H4a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2h2"></path><path d="M18 9h2a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2h-2"></path><path d="M10 6h4"></path><path d="M10 10h4"></path><path d="M10 14h4"></path><path d="M10 18h4"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="text-2xl text-foreground hover:text-primary transition-colors" aria-label="LinkedIn" href="https://www.linkedin.com/in/xingcheng-zhou-64b0a6189"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-6 w-6"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></a></div></div><div class="flex flex-col items-center md:items-end"><div class="relative w-full aspect-square max-w-[250px] rounded-lg overflow-hidden shadow-lg mb-4 bg-background"><img src="/xingcheng.github.io/assets/img/profile.jpg" alt="Xingcheng Zhou" class="w-full h-full object-cover"/></div></div></div></section><section class="py-8"><h2 class="mb-4 text-2xl font-bold">News</h2><div class="overflow-x-auto"><table class="w-full border-collapse"><tbody><tr class="border-b"><td class="py-2 pr-8 font-medium align-top min-w-[120px]">May 2025</td><td class="py-2">One paper accepted by <a href="https://icml.cc/" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">ICML 2025</a> in Vancouver, Canada!</td></tr><tr class="border-b"><td class="py-2 pr-8 font-medium align-top min-w-[120px]">Jul 2024</td><td class="py-2">One paper accepted by <a href="https://www.ieee-itsc2024.org/" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">IEEE-ITSC 2024</a> in Edmonton, Canada!</td></tr><tr class="border-b"><td class="py-2 pr-8 font-medium align-top min-w-[120px]">May 2024</td><td class="py-2">One paper accepted by <a href="https://ieee-itss.org/pub/t-iv/" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">T-IV</a>. One paper accepted by <a href="https://cvpr.thecvf.com/Conferences/2024" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">CVPR 2024</a>!</td></tr><tr class="border-b"><td class="py-2 pr-8 font-medium align-top min-w-[120px]">May 2023</td><td class="py-2">I start my PhD at TUM <a href="https://www.ce.cit.tum.de/en/air/home/" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">Chair of Robotics, Artificial Intelligence and Real time Systems</a>!</td></tr><tr class="border-b"><td class="py-2 pr-8 font-medium align-top min-w-[120px]">Jun 2021</td><td class="py-2">Completed my M.Sc. thesis &quot;Real-Time LiDAR-Based 3D Object Detection on the Highway&quot; at TUM!</td></tr></tbody></table></div></section><section id="publications" class="py-8 scroll-mt-20"><h2 class="mb-4 text-2xl font-bold"><a class="hover:text-primary" href="/xingcheng.github.io#publications">Selected Publications</a></h2><div class="space-y-6"><div class="mb-6 pb-6 border-b last:border-0"><div class="grid gap-6 md:grid-cols-[432px_1fr]"><div class="w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center"><img src="/xingcheng.github.io/assets/img/publications/tumtraffic-videoqa.jpg" alt="TUMTraffic VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes" class="max-w-full max-h-full w-auto h-auto object-contain" loading="lazy" style="display:block"/></div><div class="flex-1"><div class="mb-2"><div class="font-semibold text-lg mb-1">TUMTraffic VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes</div><div class="text-sm text-muted-foreground mb-1"><span><strong>Xingcheng Zhou</strong>, </span><span><span>Konstantinos Larintzakis</span>, </span><span><span>Hao Guo</span>, </span><span><span>Walter Zimmer</span>, </span><span><span>Mingyu Liu</span>, </span><span><span>Hu Cao</span>, </span><span><span>Jiajie Zhang</span>, </span><span><span>Venkatnarayanan Lakshminarasimhan</span>, </span><span><span>Leah Strand</span>, </span><span><span>Alois C Knoll</span></span></div><div class="text-sm italic text-muted-foreground mb-2"><em>ICML Poster</em>, <!-- -->2025</div></div><div class="flex flex-wrap gap-2 mb-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://traffix-videoqa.github.io/">Project<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://openreview.net/forum?id=Yfoi5O68rf">OpenReview<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div><div class="mb-6 pb-6 border-b last:border-0"><div class="grid gap-6 md:grid-cols-[432px_1fr]"><div class="w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center"><img src="/xingcheng.github.io/assets/img/publications/opendrivevla.jpg" alt="OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model" class="max-w-full max-h-full w-auto h-auto object-contain" loading="lazy" style="display:block"/></div><div class="flex-1"><div class="mb-2"><div class="font-semibold text-lg mb-1">OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model</div><div class="text-sm text-muted-foreground mb-1"><span><strong>Xingcheng Zhou</strong>, </span><span><span>Xuyuan Han</span>, </span><span><span>Feng Yang</span>, </span><span><span>Yunpu Ma</span>, </span><span><span>Alois C Knoll</span></span></div><div class="text-sm italic text-muted-foreground mb-2"><em>arXiv</em>, <!-- -->2025</div></div><div class="flex flex-wrap gap-2 mb-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://arxiv.org/abs/2503.23463">Paper<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://github.com/DriveVLA/OpenDriveVLA">Code<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://drivevla.github.io">Project<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div><div class="mb-6 pb-6 border-b last:border-0"><div class="grid gap-6 md:grid-cols-[432px_1fr]"><div class="w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center"><img src="/xingcheng.github.io/assets/img/publications/vlmsurvey.jpg" alt="Vision Language Models in Autonomous Driving: A Survey and Outlook" class="max-w-full max-h-full w-auto h-auto object-contain" loading="lazy" style="display:block"/></div><div class="flex-1"><div class="mb-2"><div class="font-semibold text-lg mb-1">Vision Language Models in Autonomous Driving: A Survey and Outlook</div><div class="text-sm text-muted-foreground mb-1"><span><strong>Xingcheng Zhou</strong>, </span><span><span>Mingyu Liu</span>, </span><span><span>Ekim Yurtsever</span>, </span><span><span>Bare Luka Zagar</span>, </span><span><span>Walter Zimmer</span>, </span><span><span>Hu Cao</span>, </span><span><span>Alois C Knoll</span></span></div><div class="text-sm italic text-muted-foreground mb-2"><em>T-IV</em>, <!-- -->2024</div></div><div class="flex flex-wrap gap-2 mb-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://ieeexplore.ieee.org/document/10531702">Paper<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://github.com/ge25nab/Awesome-VLM-AD-ITS">Github<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div><div class="mb-6 pb-6 border-b last:border-0"><div class="grid gap-6 md:grid-cols-[432px_1fr]"><div class="w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center"><img src="/xingcheng.github.io/assets/img/publications/warm3d.jpg" alt="WARM-3D: A Weakly-Supervised Sim2Real Domain Adaptation Framework for Roadside Monocular 3D Object Detection" class="max-w-full max-h-full w-auto h-auto object-contain" loading="lazy" style="display:block"/></div><div class="flex-1"><div class="mb-2"><div class="font-semibold text-lg mb-1">WARM-3D: A Weakly-Supervised Sim2Real Domain Adaptation Framework for Roadside Monocular 3D Object Detection</div><div class="text-sm text-muted-foreground mb-1"><span><strong>Xingcheng Zhou*</strong>, </span><span><span>Deyu Fu*</span>, </span><span><span>Walter Zimmer</span>, </span><span><span>Hao Guo</span>, </span><span><span>Hu Cao</span>, </span><span><span>Alois C Knoll</span></span></div><div class="text-sm italic text-muted-foreground mb-2"><em>ITSC</em>, <!-- -->2024</div></div><div class="flex flex-wrap gap-2 mb-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://ieeexplore.ieee.org/document/10919929">Paper<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs" href="https://warm-3d.github.io/">Project<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></section><section id="national-projects" class="py-8 scroll-mt-20"><h2 class="mb-4 text-2xl font-bold"><a class="hover:text-primary" href="/xingcheng.github.io#national-projects">National Projects</a></h2><div class="space-y-6"><div class="mb-6 pb-6 border-b last:border-0"><div class="grid gap-6 md:grid-cols-[240px_1fr]"><div class="w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[320px] flex items-center justify-center"><img src="/xingcheng.github.io/assets/img/projects/autotech.png" alt="AutoTech.agil" class="max-w-full max-h-full w-auto h-auto object-contain" loading="lazy" style="display:block;width:80%;height:auto"/></div><div class="flex-1"><div class="mb-2"><div class="font-semibold text-lg mb-1">AutoTech.agil</div><div class="text-sm text-muted-foreground mb-1"><strong>Time:</strong> <!-- -->May 2023 to Oct 2025</div><div class="text-sm text-muted-foreground mb-2"><strong>Funder:</strong> <!-- -->German Federal Ministry of Education and Research BMBF</div></div><p class="text-sm text-muted-foreground mb-3">Extend a real time traffic digital twin for connected intelligent infrastructure.</p><div class="flex flex-wrap gap-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1" href="https://www.autotechagil.de/">Website<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1" href="https://www.ce.cit.tum.de/air/research/autotechagil/">TUM Page<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div><div class="mb-6 pb-6 border-b last:border-0"><div class="grid gap-6 md:grid-cols-[240px_1fr]"><div class="w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[320px] flex items-center justify-center"><img src="/xingcheng.github.io/assets/img/projects/providentia.png" alt="Providentia++" class="max-w-full max-h-full w-auto h-auto object-contain" loading="lazy" style="display:block;width:80%;height:auto"/></div><div class="flex-1"><div class="mb-2"><div class="font-semibold text-lg mb-1">Providentia++</div><div class="text-sm text-muted-foreground mb-1"><strong>Time:</strong> <!-- -->Oct 2020 to Jun 2021</div><div class="text-sm text-muted-foreground mb-2"><strong>Funder:</strong> <!-- -->Federal Ministry of Transport and Intelligent Infrastructure BMVI</div></div><p class="text-sm text-muted-foreground mb-3">Design and implement real time 3D object detection for roadside LiDAR on highways.</p><div class="flex flex-wrap gap-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1" href="https://innovation-mobility.com/en/">Website<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1" href="https://testfeld-a9.live/kreuzung">Live stream<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div><script type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"Project","name":"AutoTech.agil","startDate":"2023-05","endDate":"2025-10","funder":{"@type":"Organization","name":"German Federal Ministry of Education and Research BMBF"},"description":"Extend a real time traffic digital twin for connected intelligent infrastructure.","url":"https://www.ce.cit.tum.de/air/research/autotechagil/"},{"@type":"Project","name":"Providentia++","startDate":"2020-10","endDate":"2025-10","funder":{"@type":"Organization","name":"Federal Ministry of Transport and Intelligent Infrastructure BMVI"},"description":"Design and implement real time 3D object detection for roadside LiDAR on highways.","url":"https://testfeld-a9.live/kreuzung"}]}</script></section><section id="academic-service" class="py-8 scroll-mt-20"><h2 class="mb-4 text-2xl font-bold"><a class="hover:text-primary" href="/xingcheng.github.io#academic-service">Academic Service</a></h2><div class="mb-8"><h3 class="mb-4 text-xl font-semibold">Workshops</h3><div class="grid grid-cols-1 md:grid-cols-2 gap-6"><div class="border rounded-lg p-4 bg-card"><div class="mb-2"><div class="font-semibold text-lg mb-1">DriveX Workshop</div><div class="text-sm text-muted-foreground mb-2">Organizer<!-- --> • <!-- -->CVPR and ICCV<!-- --> • <!-- -->2025</div></div><p class="text-sm text-muted-foreground mb-3">Foundation Models for V2X based cooperative autonomous driving</p><div class="flex items-start gap-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1" href="https://drivex-workshop.github.io/">Website<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><div class="border rounded-lg p-4 bg-card"><div class="mb-2"><div class="font-semibold text-lg mb-1">DDIVA Workshop</div><div class="text-sm text-muted-foreground mb-2">Organizer<!-- --> • <!-- -->IEEE Intelligent Vehicles Symposium<!-- --> • <!-- -->2024</div></div><p class="text-sm text-muted-foreground mb-3">Data Driven Intelligent Vehicle Applications</p><div class="flex items-start gap-2"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1" href="https://www.ce.cit.tum.de/air/research/ddiva/ddiva24/">Website<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3 w-3"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div><div><h3 class="mb-4 text-xl font-semibold">Reviewer</h3><div class="space-y-2"><div class="flex flex-wrap gap-2"><span class="text-sm px-3 py-1 rounded border bg-muted">CVPR</span><span class="text-sm px-3 py-1 rounded border bg-muted">ICCV</span><span class="text-sm px-3 py-1 rounded border bg-muted">AAAI</span><span class="text-sm px-3 py-1 rounded border bg-muted">ITSC</span><span class="text-sm px-3 py-1 rounded border bg-muted">IV</span><span class="text-sm px-3 py-1 rounded border bg-muted">IROS</span><span class="text-sm px-3 py-1 rounded border bg-muted">RA-L</span><span class="text-sm px-3 py-1 rounded border bg-muted">TRB</span><span class="text-sm px-3 py-1 rounded border bg-muted">T-IV</span></div></div></div></section></div></main><footer class="border-t bg-background"><div class="container mx-auto px-4 py-8"></div><div class="mt-8 border-t pt-8 pb-8"><div class="text-center space-y-4"><h3 class="text-lg font-semibold mb-4">Visitor Statistics</h3><div id="clustrmaps-container" class="w-full max-w-[144px] mx-auto h-[192px] bg-muted/30 rounded-lg overflow-hidden flex items-center justify-center"><div class="text-sm text-muted-foreground text-center py-4">Loading visitor map...</div></div><div class="mt-4 text-xs text-muted-foreground"><p>Visitor location map powered by<!-- --> <a href="https://clustrmaps.com/" target="_blank" rel="noopener noreferrer" class="text-primary hover:underline">ClustrMaps</a></p></div></div></div></footer></div><script src="/xingcheng.github.io/_next/static/chunks/webpack-d345df75e1a7ed31.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/xingcheng.github.io/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/xingcheng.github.io/_next/static/css/bced8c83fdf6512f.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[2846,[],\"\"]\n5:\"$Sreact.fragment\"\n6:I[2972,[\"254\",\"static/chunks/254-87337e6e5877cb9f.js\",\"931\",\"static/chunks/app/page-af3d24cbd518d795.js\"],\"\"]\n7:I[6479,[\"254\",\"static/chunks/254-87337e6e5877cb9f.js\",\"931\",\"static/chunks/app/page-af3d24cbd518d795.js\"],\"NationalProjectCard\"]\n8:I[7400,[\"254\",\"static/chunks/254-87337e6e5877cb9f.js\",\"931\",\"static/chunks/app/page-af3d24cbd518d795.js\"],\"WorkshopCard\"]\n9:I[2798,[\"254\",\"static/chunks/254-87337e6e5877cb9f.js\",\"185\",\"static/chunks/app/layout-dfcfffdb162e0cfc.js\"],\"ThemeProvider\"]\na:I[4945,[\"254\",\"static/chunks/254-87337e6e5877cb9f.js\",\"185\",\"static/chunks/app/layout-dfcfffdb162e0cfc.js\"],\"Navigation\"]\nb:I[4707,[],\"\"]\nc:I[6423,[],\"\"]\nd:I[7466,[\"254\",\"static/chunks/254-87337e6e5877cb9f.js\",\"185\",\"static/chunks/app/layout-dfcfffdb162e0cfc.js\"],\"ClustrMapsWidget\"]\nf:I[1060,[],\"\"]\n10:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L3\",null,{\"buildId\":\"RDD0kxU6KUHg8sUMeRZsR\",\"assetPrefix\":\"/xingcheng.github.io\",\"urlParts\":[\"\",\"\"],\"initialTree\":[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"__PAGE__\",{},[[\"$L4\",[\"$\",\"div\",null,{\"className\":\"container mx-auto px-4 py-8\",\"children\":[[\"$\",\"section\",null,{\"className\":\"py-12 border-b\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid gap-8 md:grid-cols-[1fr_250px]\",\"children\":[[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"prose prose-lg max-w-none dark:prose-invert\",\"children\":[[\"$\",\"$5\",\"0\",{\"children\":[\"$\",\"p\",null,{\"children\":[\"Hi, I am Xingcheng Zhou. I joined the \",[\"$\",\"a\",\"0\",{\"href\":\"https://www.ce.cit.tum.de/air/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"Chair of Robotics, Artificial Intelligence and Real time Systems\"}],\" at Technical University of Munich in 2023 as a Research Associate, working under the supervision of \",[\"$\",\"a\",\"1\",{\"href\":\"https://www.ce.cit.tum.de/air/people/alois-knoll\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"Prof. Dr. Ing. habil. Alois Christian Knoll\"}],\".\"]}]}],[\"$\",\"$5\",\"1\",{\"children\":[\"$\",\"p\",null,{\"children\":[\"My research interests include Vision Language Models, 3D Environment Perception, Scene Understanding, World Models and related areas.\"]}]}],[\"$\",\"$5\",\"2\",{\"children\":[\"$\",\"p\",null,{\"children\":[\"I completed my M.Sc. in Electrical and Computer Engineering at the \",[\"$\",\"a\",\"0\",{\"href\":\"https://www.tum.de\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"Technical University of Munich\"}],\" in 2021. Before joining TUM, I worked as an Industrial AI Researcher at \",[\"$\",\"a\",\"1\",{\"href\":\"https://www.siemens.com\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"Siemens\"}],\".\"]}]}]]}],[\"$\",\"ul\",null,{\"className\":\"space-y-1 text-sm\",\"children\":[\"$\",\"li\",null,{\"children\":[\"email:\",\" \",[\"$\",\"a\",null,{\"href\":\"mailto:xingcheng.zhou@tum.de\",\"className\":\"text-primary hover:underline\",\"children\":\"xingcheng[dot]zhou{at}tum[dot]de\"}]]}]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-4 items-center\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"mailto:xingcheng.zhou@tum.de\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-2xl text-foreground hover:text-primary transition-colors\",\"aria-label\":\"Email\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail h-6 w-6\",\"children\":[[\"$\",\"rect\",\"18n3k1\",{\"width\":\"20\",\"height\":\"16\",\"x\":\"2\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"1ocrg3\",{\"d\":\"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7\"}],\"$undefined\"]}]}],[\"$\",\"$L6\",null,{\"href\":\"https://scholar.google.com/citations?user=FPYXLpQAAAAJ\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-2xl text-foreground hover:text-primary transition-colors\",\"aria-label\":\"Google Scholar\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-graduation-cap h-6 w-6\",\"children\":[[\"$\",\"path\",\"j76jl0\",{\"d\":\"M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z\"}],[\"$\",\"path\",\"1lu8f3\",{\"d\":\"M22 10v6\"}],[\"$\",\"path\",\"1r8lef\",{\"d\":\"M6 12.5V16a6 3 0 0 0 12 0v-3.5\"}],\"$undefined\"]}]}],[\"$\",\"$L6\",null,{\"href\":\"https://github.com/ge25nab\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-2xl text-foreground hover:text-primary transition-colors\",\"aria-label\":\"GitHub\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-6 w-6\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}],[\"$\",\"$L6\",null,{\"href\":\"https://www.ce.cit.tum.de/air/people/xingcheng-zhou-msc/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-2xl text-foreground hover:text-primary transition-colors\",\"aria-label\":\"TUM Profile\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-building2 h-6 w-6\",\"children\":[[\"$\",\"path\",\"1b4qmf\",{\"d\":\"M6 22V4a2 2 0 0 1 2-2h8a2 2 0 0 1 2 2v18Z\"}],[\"$\",\"path\",\"i71pzd\",{\"d\":\"M6 12H4a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2h2\"}],[\"$\",\"path\",\"10jefs\",{\"d\":\"M18 9h2a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2h-2\"}],[\"$\",\"path\",\"1itunk\",{\"d\":\"M10 6h4\"}],[\"$\",\"path\",\"tcdvrf\",{\"d\":\"M10 10h4\"}],[\"$\",\"path\",\"kelpxr\",{\"d\":\"M10 14h4\"}],[\"$\",\"path\",\"1ulq68\",{\"d\":\"M10 18h4\"}],\"$undefined\"]}]}],[\"$\",\"$L6\",null,{\"href\":\"https://www.linkedin.com/in/xingcheng-zhou-64b0a6189\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-2xl text-foreground hover:text-primary transition-colors\",\"aria-label\":\"LinkedIn\",\"children\":[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-linkedin h-6 w-6\",\"children\":[[\"$\",\"path\",\"c2jq9f\",{\"d\":\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"}],[\"$\",\"rect\",\"mk3on5\",{\"width\":\"4\",\"height\":\"12\",\"x\":\"2\",\"y\":\"9\"}],[\"$\",\"circle\",\"bt5ra8\",{\"cx\":\"4\",\"cy\":\"4\",\"r\":\"2\"}],\"$undefined\"]}]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center md:items-end\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative w-full aspect-square max-w-[250px] rounded-lg overflow-hidden shadow-lg mb-4 bg-background\",\"children\":[\"$\",\"img\",null,{\"src\":\"/xingcheng.github.io/assets/img/profile.jpg\",\"alt\":\"Xingcheng Zhou\",\"className\":\"w-full h-full object-cover\"}]}]}]]}]}],[\"$\",\"section\",null,{\"className\":\"py-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"mb-4 text-2xl font-bold\",\"children\":\"News\"}],[\"$\",\"div\",null,{\"className\":\"overflow-x-auto\",\"children\":[\"$\",\"table\",null,{\"className\":\"w-full border-collapse\",\"children\":[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",\"0\",{\"className\":\"border-b\",\"children\":[[\"$\",\"td\",null,{\"className\":\"py-2 pr-8 font-medium align-top min-w-[120px]\",\"children\":\"May 2025\"}],[\"$\",\"td\",null,{\"className\":\"py-2\",\"children\":[\"One paper accepted by \",[\"$\",\"a\",\"0\",{\"href\":\"https://icml.cc/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"ICML 2025\"}],\" in Vancouver, Canada!\"]}]]}],[\"$\",\"tr\",\"1\",{\"className\":\"border-b\",\"children\":[[\"$\",\"td\",null,{\"className\":\"py-2 pr-8 font-medium align-top min-w-[120px]\",\"children\":\"Jul 2024\"}],[\"$\",\"td\",null,{\"className\":\"py-2\",\"children\":[\"One paper accepted by \",[\"$\",\"a\",\"0\",{\"href\":\"https://www.ieee-itsc2024.org/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"IEEE-ITSC 2024\"}],\" in Edmonton, Canada!\"]}]]}],[\"$\",\"tr\",\"2\",{\"className\":\"border-b\",\"children\":[[\"$\",\"td\",null,{\"className\":\"py-2 pr-8 font-medium align-top min-w-[120px]\",\"children\":\"May 2024\"}],[\"$\",\"td\",null,{\"className\":\"py-2\",\"children\":[\"One paper accepted by \",[\"$\",\"a\",\"0\",{\"href\":\"https://ieee-itss.org/pub/t-iv/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"T-IV\"}],\". One paper accepted by \",[\"$\",\"a\",\"1\",{\"href\":\"https://cvpr.thecvf.com/Conferences/2024\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"CVPR 2024\"}],\"!\"]}]]}],[\"$\",\"tr\",\"3\",{\"className\":\"border-b\",\"children\":[[\"$\",\"td\",null,{\"className\":\"py-2 pr-8 font-medium align-top min-w-[120px]\",\"children\":\"May 2023\"}],[\"$\",\"td\",null,{\"className\":\"py-2\",\"children\":[\"I start my PhD at TUM \",[\"$\",\"a\",\"0\",{\"href\":\"https://www.ce.cit.tum.de/en/air/home/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-primary hover:underline\",\"children\":\"Chair of Robotics, Artificial Intelligence and Real time Systems\"}],\"!\"]}]]}],[\"$\",\"tr\",\"4\",{\"className\":\"border-b\",\"children\":[[\"$\",\"td\",null,{\"className\":\"py-2 pr-8 font-medium align-top min-w-[120px]\",\"children\":\"Jun 2021\"}],[\"$\",\"td\",null,{\"className\":\"py-2\",\"children\":\"Completed my M.Sc. thesis \\\"Real-Time LiDAR-Based 3D Object Detection on the Highway\\\" at TUM!\"}]]}]]}]}]}]]}],[\"$\",\"section\",null,{\"id\":\"publications\",\"className\":\"py-8 scroll-mt-20\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"mb-4 text-2xl font-bold\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/#publications\",\"className\":\"hover:text-primary\",\"children\":\"Selected Publications\"}]}],[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-6 pb-6 border-b last:border-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-[432px_1fr]\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center\",\"children\":[\"$\",\"img\",null,{\"src\":\"/xingcheng.github.io/assets/img/publications/tumtraffic-videoqa.jpg\",\"alt\":\"TUMTraffic VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes\",\"className\":\"max-w-full max-h-full w-auto h-auto object-contain\",\"loading\":\"lazy\",\"style\":{\"display\":\"block\"}}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"font-semibold text-lg mb-1\",\"children\":\"TUMTraffic VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes\"}],[\"$\",\"div\",null,{\"className\":\"text-sm text-muted-foreground mb-1\",\"children\":[[\"$\",\"span\",\"0\",{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Xingcheng Zhou\"}],\", \"]}],[\"$\",\"span\",\"1\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Konstantinos Larintzakis\"}],\", \"]}],[\"$\",\"span\",\"2\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Hao Guo\"}],\", \"]}],[\"$\",\"span\",\"3\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Walter Zimmer\"}],\", \"]}],[\"$\",\"span\",\"4\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Mingyu Liu\"}],\", \"]}],[\"$\",\"span\",\"5\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Hu Cao\"}],\", \"]}],[\"$\",\"span\",\"6\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Jiajie Zhang\"}],\", \"]}],[\"$\",\"span\",\"7\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Venkatnarayanan Lakshminarasimhan\"}],\", \"]}],[\"$\",\"span\",\"8\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Leah Strand\"}],\", \"]}],[\"$\",\"span\",\"9\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Alois C Knoll\"}],false]}]]}],[\"$\",\"div\",null,{\"className\":\"text-sm italic text-muted-foreground mb-2\",\"children\":[[\"$\",\"em\",null,{\"children\":\"ICML Poster\"}],\", \",2025]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-2\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"https://traffix-videoqa.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Project\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}],[\"$\",\"$L6\",null,{\"href\":\"https://openreview.net/forum?id=Yfoi5O68rf\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"OpenReview\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}]]}],\"$undefined\"]}]]}]}],[\"$\",\"div\",null,{\"className\":\"mb-6 pb-6 border-b last:border-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-[432px_1fr]\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center\",\"children\":[\"$\",\"img\",null,{\"src\":\"/xingcheng.github.io/assets/img/publications/opendrivevla.jpg\",\"alt\":\"OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model\",\"className\":\"max-w-full max-h-full w-auto h-auto object-contain\",\"loading\":\"lazy\",\"style\":{\"display\":\"block\"}}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"font-semibold text-lg mb-1\",\"children\":\"OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model\"}],[\"$\",\"div\",null,{\"className\":\"text-sm text-muted-foreground mb-1\",\"children\":[[\"$\",\"span\",\"0\",{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Xingcheng Zhou\"}],\", \"]}],[\"$\",\"span\",\"1\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Xuyuan Han\"}],\", \"]}],[\"$\",\"span\",\"2\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Feng Yang\"}],\", \"]}],[\"$\",\"span\",\"3\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Yunpu Ma\"}],\", \"]}],[\"$\",\"span\",\"4\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Alois C Knoll\"}],false]}]]}],[\"$\",\"div\",null,{\"className\":\"text-sm italic text-muted-foreground mb-2\",\"children\":[[\"$\",\"em\",null,{\"children\":\"arXiv\"}],\", \",2025]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-2\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"https://arxiv.org/abs/2503.23463\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Paper\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}],[\"$\",\"$L6\",null,{\"href\":\"https://github.com/DriveVLA/OpenDriveVLA\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Code\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}],[\"$\",\"$L6\",null,{\"href\":\"https://drivevla.github.io\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Project\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}]]}],\"$undefined\"]}]]}]}],[\"$\",\"div\",null,{\"className\":\"mb-6 pb-6 border-b last:border-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-[432px_1fr]\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center\",\"children\":[\"$\",\"img\",null,{\"src\":\"/xingcheng.github.io/assets/img/publications/vlmsurvey.jpg\",\"alt\":\"Vision Language Models in Autonomous Driving: A Survey and Outlook\",\"className\":\"max-w-full max-h-full w-auto h-auto object-contain\",\"loading\":\"lazy\",\"style\":{\"display\":\"block\"}}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"font-semibold text-lg mb-1\",\"children\":\"Vision Language Models in Autonomous Driving: A Survey and Outlook\"}],[\"$\",\"div\",null,{\"className\":\"text-sm text-muted-foreground mb-1\",\"children\":[[\"$\",\"span\",\"0\",{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Xingcheng Zhou\"}],\", \"]}],[\"$\",\"span\",\"1\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Mingyu Liu\"}],\", \"]}],[\"$\",\"span\",\"2\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Ekim Yurtsever\"}],\", \"]}],[\"$\",\"span\",\"3\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Bare Luka Zagar\"}],\", \"]}],[\"$\",\"span\",\"4\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Walter Zimmer\"}],\", \"]}],[\"$\",\"span\",\"5\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Hu Cao\"}],\", \"]}],[\"$\",\"span\",\"6\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Alois C Knoll\"}],false]}]]}],[\"$\",\"div\",null,{\"className\":\"text-sm italic text-muted-foreground mb-2\",\"children\":[[\"$\",\"em\",null,{\"children\":\"T-IV\"}],\", \",2024]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-2\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"https://ieeexplore.ieee.org/document/10531702\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Paper\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}],[\"$\",\"$L6\",null,{\"href\":\"https://github.com/ge25nab/Awesome-VLM-AD-ITS\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Github\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}]]}],\"$undefined\"]}]]}]}],[\"$\",\"div\",null,{\"className\":\"mb-6 pb-6 border-b last:border-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid gap-6 md:grid-cols-[432px_1fr]\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full rounded-lg overflow-hidden bg-background flex-shrink-0 max-h-[576px] flex items-center justify-center\",\"children\":[\"$\",\"img\",null,{\"src\":\"/xingcheng.github.io/assets/img/publications/warm3d.jpg\",\"alt\":\"WARM-3D: A Weakly-Supervised Sim2Real Domain Adaptation Framework for Roadside Monocular 3D Object Detection\",\"className\":\"max-w-full max-h-full w-auto h-auto object-contain\",\"loading\":\"lazy\",\"style\":{\"display\":\"block\"}}]}],[\"$\",\"div\",null,{\"className\":\"flex-1\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"font-semibold text-lg mb-1\",\"children\":\"WARM-3D: A Weakly-Supervised Sim2Real Domain Adaptation Framework for Roadside Monocular 3D Object Detection\"}],[\"$\",\"div\",null,{\"className\":\"text-sm text-muted-foreground mb-1\",\"children\":[[\"$\",\"span\",\"0\",{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Xingcheng Zhou*\"}],\", \"]}],[\"$\",\"span\",\"1\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Deyu Fu*\"}],\", \"]}],[\"$\",\"span\",\"2\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Walter Zimmer\"}],\", \"]}],[\"$\",\"span\",\"3\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Hao Guo\"}],\", \"]}],[\"$\",\"span\",\"4\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Hu Cao\"}],\", \"]}],[\"$\",\"span\",\"5\",{\"children\":[[\"$\",\"span\",null,{\"children\":\"Alois C Knoll\"}],false]}]]}],[\"$\",\"div\",null,{\"className\":\"text-sm italic text-muted-foreground mb-2\",\"children\":[[\"$\",\"em\",null,{\"children\":\"ITSC\"}],\", \",2024]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-2\",\"children\":[[\"$\",\"$L6\",null,{\"href\":\"https://ieeexplore.ieee.org/document/10919929\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Paper\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}],[\"$\",\"$L6\",null,{\"href\":\"https://warm-3d.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3 inline-flex items-center gap-1 text-xs\",\"children\":[\"Project\",[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-external-link h-3 w-3\",\"children\":[[\"$\",\"path\",\"1q9fwt\",{\"d\":\"M15 3h6v6\"}],[\"$\",\"path\",\"gplh6r\",{\"d\":\"M10 14 21 3\"}],[\"$\",\"path\",\"a6xqqp\",{\"d\":\"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6\"}],\"$undefined\"]}]]}]]}],\"$undefined\"]}]]}]}]]}]]}],[\"$\",\"section\",null,{\"id\":\"national-projects\",\"className\":\"py-8 scroll-mt-20\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"mb-4 text-2xl font-bold\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/#national-projects\",\"className\":\"hover:text-primary\",\"children\":\"National Projects\"}]}],\"\",[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[[\"$\",\"$L7\",\"0\",{\"project\":{\"title\":\"AutoTech.agil\",\"timeframe\":\"May 2023 to Oct 2025\",\"funder\":\"German Federal Ministry of Education and Research BMBF\",\"summary\":\"Extend a real time traffic digital twin for connected intelligent infrastructure.\",\"links\":[{\"label\":\"TUM Page\",\"url\":\"https://www.ce.cit.tum.de/air/research/autotechagil/\"}],\"image\":\"/assets/img/projects/autotech.png\",\"website\":\"https://www.autotechagil.de/\"}}],[\"$\",\"$L7\",\"1\",{\"project\":{\"title\":\"Providentia++\",\"timeframe\":\"Oct 2020 to Jun 2021\",\"funder\":\"Federal Ministry of Transport and Intelligent Infrastructure BMVI\",\"summary\":\"Design and implement real time 3D object detection for roadside LiDAR on highways.\",\"links\":[{\"label\":\"Live stream\",\"url\":\"https://testfeld-a9.live/kreuzung\"}],\"image\":\"/assets/img/projects/providentia.png\",\"website\":\"https://innovation-mobility.com/en/\"}}]]}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@graph\\\":[{\\\"@type\\\":\\\"Project\\\",\\\"name\\\":\\\"AutoTech.agil\\\",\\\"startDate\\\":\\\"2023-05\\\",\\\"endDate\\\":\\\"2025-10\\\",\\\"funder\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"German Federal Ministry of Education and Research BMBF\\\"},\\\"description\\\":\\\"Extend a real time traffic digital twin for connected intelligent infrastructure.\\\",\\\"url\\\":\\\"https://www.ce.cit.tum.de/air/research/autotechagil/\\\"},{\\\"@type\\\":\\\"Project\\\",\\\"name\\\":\\\"Providentia++\\\",\\\"startDate\\\":\\\"2020-10\\\",\\\"endDate\\\":\\\"2025-10\\\",\\\"funder\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"Federal Ministry of Transport and Intelligent Infrastructure BMVI\\\"},\\\"description\\\":\\\"Design and implement real time 3D object detection for roadside LiDAR on highways.\\\",\\\"url\\\":\\\"https://testfeld-a9.live/kreuzung\\\"}]}\"}}]]}],[\"$\",\"section\",null,{\"id\":\"academic-service\",\"className\":\"py-8 scroll-mt-20\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"mb-4 text-2xl font-bold\",\"children\":[\"$\",\"$L6\",null,{\"href\":\"/#academic-service\",\"className\":\"hover:text-primary\",\"children\":\"Academic Service\"}]}],[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-4 text-xl font-semibold\",\"children\":\"Workshops\"}],[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-2 gap-6\",\"children\":[[\"$\",\"$L8\",\"0\",{\"workshop\":{\"title\":\"DriveX Workshop\",\"role\":\"Organizer\",\"venue\":\"CVPR and ICCV\",\"year\":\"2025\",\"theme\":\"Foundation Models for V2X based cooperative autonomous driving\",\"links\":[{\"label\":\"Website\",\"url\":\"https://drivex-workshop.github.io/\"}]}}],[\"$\",\"$L8\",\"1\",{\"workshop\":{\"title\":\"DDIVA Workshop\",\"role\":\"Organizer\",\"venue\":\"IEEE Intelligent Vehicles Symposium\",\"year\":\"2024\",\"theme\":\"Data Driven Intelligent Vehicle Applications\",\"links\":[{\"label\":\"Website\",\"url\":\"https://www.ce.cit.tum.de/air/research/ddiva/ddiva24/\"}]}}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"mb-4 text-xl font-semibold\",\"children\":\"Reviewer\"}],[\"$\",\"div\",null,{\"className\":\"space-y-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2\",\"children\":[[\"$\",\"span\",\"0\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"CVPR\"}],[\"$\",\"span\",\"1\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"ICCV\"}],[\"$\",\"span\",\"2\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"AAAI\"}],[\"$\",\"span\",\"3\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"ITSC\"}],[\"$\",\"span\",\"4\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"IV\"}],[\"$\",\"span\",\"5\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"IROS\"}],[\"$\",\"span\",\"6\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"RA-L\"}],[\"$\",\"span\",\"7\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"TRB\"}],[\"$\",\"span\",\"8\",{\"className\":\"text-sm px-3 py-1 rounded border bg-muted\",\"children\":\"T-IV\"}]]}]}]]}]]}]]}],null],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/xingcheng.github.io/_next/static/css/bced8c83fdf6512f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/xingcheng.github.io/favicon.ico\"}]}],[\"$\",\"body\",null,{\"className\":\"__className_8dd892\",\"children\":[\"$\",\"$L9\",null,{\"attribute\":\"class\",\"defaultTheme\":\"light\",\"enableSystem\":true,\"children\":[\"$\",\"div\",null,{\"className\":\"flex min-h-screen flex-col\",\"children\":[[\"$\",\"$La\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}],[\"$\",\"footer\",null,{\"className\":\"border-t bg-background\",\"children\":[[\"$\",\"div\",null,{\"className\":\"container mx-auto px-4 py-8\"}],[\"$\",\"$Ld\",null,{}]]}]]}]}]}]]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Le\"],\"globalErrorComponent\":\"$f\",\"missingSlots\":\"$W10\"}]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Xingcheng Zhou | TUM\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Vision Language Action research for autonomous driving and intelligent infrastructure\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"Xingcheng Zhou\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"autonomous driving,vision language model,world model,trajectory planning,cooperative perception,dataset,TUM\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Xingcheng Zhou | TUM\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Vision Language Action research for autonomous driving and intelligent infrastructure\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:title\",\"content\":\"Xingcheng Zhou | TUM\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:description\",\"content\":\"Vision Language Action research for autonomous driving and intelligent infrastructure\"}],[\"$\",\"meta\",\"13\",{\"name\":\"next-size-adjust\"}]]\n4:null\n"])</script></body></html>